---
categories:
- ""
- ""
date: "2017-10-31T22:42:51-05:00"
description: Nullam et orci eu lorem consequat tincidunt vivamus et sagittis magna
  sed nunc rhoncus condimentum sem. In efficitur ligula tate urna. Maecenas massa
  sed magna lacinia magna pellentesque lorem ipsum dolor. Nullam et orci eu lorem
  consequat tincidunt. Vivamus et sagittis tempus.
draft: false
image: pic07.jpg
keywords: ""
slug: aliquam
title: Aliquam
---

```{r load-libraries, warning=FALSE, message=FALSE, echo=FALSE}
library(tidyverse)  # Load ggplot2, dplyr, and all the other tidyverse packages
library(gapminder)  # gapminder dataset
library(here)
library(janitor)
```

<!-- The goal is to test your software installation, to demonstrate competency in Markdown, and in the basics of `ggplot`. -->
-> I commented out all instructional text

# A short introduction to Louis Frach \
Hello there! My name is **Louis** and originally I am from Hamburg, Germany. You can see a picture of my hometown below:

![The city's port is one of the biggest in Europe](https://images.musement.com/cover/0002/37/hamburg-landungsbrucken-less-jpg_header-136590.jpeg?w=1200&h=630&q=95&fit=crop)

Moving to London a few days ago marks the third time that I have moved abroad for studies. During high school, I moved to **Florida**, both to improve my English skills and to play competitive tennis. After high school, I then decided to attend the University of St. Gallen in **Switzerland**. Loving to ski makes Switzerland a great country to live in! After wrapping up my degree in business administration, I completed internships in private equity and most recently an early stage venture capital fund. At LBS, I am excited to meet motivated people, contribute to the *amazing* campus community and fully immerse myself in London!   

### Here are some more quick facts about me:
1. I have *3* siblings (two brothers and one sister)
2. Spain is my favorite vacation destination 
3. I am looking to join a VC firm after graduation

In today's world it is probably easiest if you add me on [LinkedIn](https://www.linkedin.com/in/louis-frach) so that we can stay in touch and hopefully meet soon!


# Task 2: `gapminder` country comparison

<!-- You have seen the `gapminder` dataset that has data on life expectancy, population, and GDP per capita for 142 countries from 1952 to 2007. To get a glimpse of the dataframe, namely to see the variable names, variable types, etc., we use the `glimpse` function. We also want to have a look at the first 20 rows of data. -->

```{r}
glimpse(gapminder)

head(gapminder, 20) # look at the first 20 rows of the dataframe

```

<!-- Your task is to produce two graphs of how life expectancy has changed over the years for the `country` and the `continent` you come from. -->

<!-- I have created the `country_data` and `continent_data` with the code below. -->

```{r}
country_data <- gapminder %>% 
            filter(country == "Germany")

continent_data <- gapminder %>% 
            filter(continent == "Europe")
```

<!-- First, create a plot of life expectancy over time for the single country you chose. Map `year` on the x-axis, and `lifeExp` on the y-axis. You should also use `geom_point()` to see the actual data points and `geom_smooth(se = FALSE)` to plot the underlying trendlines. You need to remove the comments **\#** from the lines below for your code to run. -->

```{r, lifeExp_one_country}
plot1 <- ggplot(data = country_data, mapping = aes(x = year, y = lifeExp))+
    geom_point() +
    geom_smooth(se = FALSE)+
    NULL 
  plot1
```

<!-- Next we need to add a title. Create a new plot, or extend plot1, using the `labs()` function to add an informative title to the plot. -->

```{r, lifeExp_one_country_with_label}
 plot1<- plot1 +
   labs(title = "Life Expectancy Over Time in Germany ",
       x = "Time",
       y = "Life Expectancy") +
   NULL
plot1
```

<!-- Secondly, produce a plot for all countries in the *continent* you come from. (Hint: map the `country` variable to the colour aesthetic. You also want to map `country` to the `group` aesthetic, so all points for each country are grouped together). -->

```{r lifeExp_one_continent}
 ggplot(continent_data, mapping = aes(x = year  , y = lifeExp  , colour=country , group = country))+
   geom_point() + 
   geom_smooth(se = FALSE) +
   labs(title = "Life Expectancy Over Time in European Countries",
       x = "Time",
       y = "Life Expectancy")
```

<!-- Finally, using the original `gapminder` data, produce a life expectancy over time graph, grouped (or faceted) by continent. We will remove all legends, adding the `theme(legend.position="none")` in the end of our ggplot. -->

```{r lifeExp_facet_by_continent}
 ggplot(data = gapminder , mapping = aes(x = year  , y = lifeExp  , colour=country ))+
   geom_point() + 
   geom_smooth(se = FALSE) +
   facet_wrap(~continent) +
   theme(legend.position="none") + 
   labs(title = "Life Expectancy Over Time Across Continents",
       x = "Time",
       y = "Life Expectancy")
```

<!-- Given these trends, what can you say about life expectancy since 1952? Again, don't just say what's happening in the graph. Tell some sort of story and speculate about the differences in the patterns. -->

<!-- > Type your answer after this blockquote -->

### Trends in life expectancy since 1952
One major indicator of inequality across different continents is life expectancy. As can be seen from the graphs, life expectancy varies significantly between richer continents (i.e. Europe, Americas, Oceania) and developing continents (i.e. Africa and Asia).

While life expectancy has been increasing in all areas, different patterns can be observed: 
First, there are signs that the substantial increase in life expectancy across Asian and African countries will not continue into the future as both graphs are leveling off. This could be due to economic and geopolitical instability, which translates into problems in the healthcare sector.    

Second, the differences in life expectancy across countries are strongest in Asia and Africa. This could be due to the large disparities in economic development, education, and political systems in these continents. To contrast, these disparities are much less pronounced in Europe, where the European Union creates a more level playing field. 

Third, a life expectancy of 80 years seems to be a natural barrier, at least with current healthcare technology. Very few countries in the sample, independent of the respective continent, have a life expectancy above 80 years. However, medical progress may shift this bar even higher in the decades to come.

      

# Task 3: Brexit vote analysis

<!-- We will have a look at the results of the 2016 Brexit vote in the UK. First we read the data using `read_csv()` and have a quick glimpse at the data -->

```{r load_brexit_data, warning=FALSE, message=FALSE}
brexit_results <- read_csv(here::here("data","brexit_results.csv"))


glimpse(brexit_results)
```

<!-- The data comes from [Elliott Morris](https://www.thecrosstab.com/), who cleaned it and made it available through his [DataCamp class on analysing election and polling data in R](https://www.datacamp.com/courses/analyzing-election-and-polling-data-in-r). -->

<!-- Our main outcome variable (or y) is `leave_share`, which is the percent of votes cast in favour of Brexit, or leaving the EU. Each row is a UK [parliament constituency](https://en.wikipedia.org/wiki/United_Kingdom_Parliament_constituencies). -->

<!-- To get a sense of the spread, or distribution, of the data, we can plot a histogram, a density plot, and the empirical cumulative distribution function of the leave % in all constituencies. -->

```{r brexit_histogram, warning=FALSE, message=FALSE}

# histogram
ggplot(brexit_results, aes(x = leave_share)) +
  geom_histogram(binwidth = 2.5) + 
  labs(title = "Brexit vote results across all UK contituencies", subtitle="Histogram view",
       x = "% of votes cast in favour of Brexit",
       y = "Nr. of constituencies")

# density plot-- think smoothed histogram
ggplot(brexit_results, aes(x = leave_share)) +
  geom_density() +
  labs(title = "Brexit vote results across all UK contituencies", subtitle="Density plot view",
       x = "% of votes cast in favour of Brexit",
       y = "Share of constituencies")


# The empirical cumulative distribution function (ECDF) 
ggplot(brexit_results, aes(x = leave_share)) +
  stat_ecdf(geom = "step", pad = FALSE) +
  scale_y_continuous(labels = scales::percent) + 
    labs(title = "Brexit vote results across all UK contituencies", subtitle="Cumulative view",
       x = "% of votes cast in favour of Brexit",
       y = "Share of constituencies")


```

<!-- One common explanation for the Brexit outcome was fear of immigration and opposition to the EU's more open border policy. We can check the relationship (or correlation) between the proportion of native born residents (`born_in_uk`) in a constituency and its `leave_share`. To do this, let us get the correlation between the two variables -->

```{r brexit_immigration_correlation}
brexit_results %>% 
  select(leave_share, born_in_uk) %>% 
  cor()
```

<!-- The correlation is almost 0.5, which shows that the two variables are positively correlated. -->

<!-- We can also create a scatterplot between these two variables using `geom_point`. We also add the best fit line, using `geom_smooth(method = "lm")`. -->

```{r brexit_immigration_plot}
ggplot(brexit_results, aes(x = born_in_uk, y = leave_share)) +
  geom_point(alpha=0.3) +
  
  # add a smoothing line, and use method="lm" to get the best straight-line
  geom_smooth(method = "lm") + 
  # use a white background and frame the plot with a black box
  theme_bw() +
  # titles
  labs(title = "Relationship between native born residents in a constituency and its leave share", subtitle="Each dot represents one constituency; blue line indicates best fit",
       x = "Proportion of native born residents",
       y = "% of votes cast in favour of Brexit")
```

<!-- You have the code for the plots, I would like you to revisit all of them and use the `labs()` function to add an informative title, subtitle, and axes titles to all plots. -->

<!-- What can you say about the relationship shown above? Again, don't just say what's happening in the graph. Tell some sort of story and speculate about the differences in the patterns. -->

> Type your answer after, and outside, this blockquote.

### Commenting on the relationship between native born residents and votes cast in favour of Brexit

The EU's response to the  refugee crisis in 2015, namely a policy of open borders and mass immigration, has repeatedly been described as one of the key drivers of anti-EU sentiment in the UK. One way to verify this hypothesis is to explore the relationship between the proportion of native born residents in UK constituencies and the % of votes cast in favour of Brexit. This relationship is shown in the graph above. The blue line indicates that the higher the proportion of native born residents in a constituency, the higher is the % of votes cast in favor of Brexit. This supports the initial hypothesis that in less heterogeneous communities (with a lower proportion of foreigners), people are more skeptical to mass immigration under EU membership and hence voted in favor of Brexit. 

However, is is important to clarify that this *correlation* does not describe a *causal* relationship. One can also speculate that the demographic structure in some of the outlier constituencies (i.e., those in the top left or bottom right corner of the graph) differs from that of the rest. For instance, the mean age may be significantly lower or higher in these constituencies, which then impacts the voting results. 

Also, there are likely other factors, next to a fear of open borders, that have contributed to the described result. For instance, native born residents may be more appealed to the promise of less bureaucracy and more decision-making authority under a Brexit scenario, because they have not benefited from open borders as much as foreigners have. For future analyses it would therefore be helpful to explore the data in greater detail, for instance by adding information on the average income level for each constituency.                 


# Task 4: Animal rescue incidents attended by the London Fire Brigade

<!-- [The London Fire Brigade](https://data.london.gov.uk/dataset/animal-rescue-incidents-attended-by-lfb) attends a range of non-fire incidents (which we call 'special services'). These 'special services' include assistance to animals that may be trapped or in distress. The data is provided from January 2009 and is updated monthly. A range of information is supplied for each incident including some location information (postcode, borough, ward), as well as the data/time of the incidents. We do not routinely record data about animal deaths or injuries. -->

<!-- Please note that any cost included is a notional cost calculated based on the length of time rounded up to the nearest hour spent by Pump, Aerial and FRU appliances at the incident and charged at the current Brigade hourly rate. -->

```{r load_animal_rescue_data, warning=FALSE, message=FALSE}

url <- "https://data.london.gov.uk/download/animal-rescue-incidents-attended-by-lfb/8a7d91c2-9aec-4bde-937a-3998f4717cd8/Animal%20Rescue%20incidents%20attended%20by%20LFB%20from%20Jan%202009.csv"

animal_rescue <- read_csv(url,
                          locale = locale(encoding = "CP1252")) %>% 
  janitor::clean_names()


glimpse(animal_rescue)
```
<!-- One of the more useful things one can do with any data set is quick counts, namely to see how many observations fall within one category. For instance, if we wanted to count the number of incidents by year, we would either use `group_by()... summarise()` or, simply [`count()`](https://dplyr.tidyverse.org/reference/count.html) -->

```{r, instances_by_calendar_year}

animal_rescue %>% 
  dplyr::group_by(cal_year) %>% 
  summarise(count=n())

animal_rescue %>% 
  count(cal_year, name="count")

```

<!-- Let us try to see how many incidents we have by animal group. Again, we can do this either using group_by() and summarise(), or by using count() -->

```{r, animal_group_percentages}
animal_rescue %>% 
  group_by(animal_group_parent) %>% 
  
  #group_by and summarise will produce a new column with the count in each animal group
  summarise(count = n()) %>% 
  
  # mutate adds a new column; here we calculate the percentage
  mutate(percent = round(100*count/sum(count),2)) %>% 
  
  # arrange() sorts the data by percent. Since the default sorting is min to max and we would like to see it sorted
  # in descending order (max to min), we use arrange(desc()) 
  arrange(desc(percent))


animal_rescue %>% 
  
  #count does the same thing as group_by and summarise
  # name = "count" will call the column with the counts "count" ( exciting, I know)
  # and 'sort=TRUE' will sort them from max to min
  count(animal_group_parent, name="count", sort=TRUE) %>% 
  mutate(percent = round(100*count/sum(count),2))


```

<!-- Do you see anything strange in these tables?  -->

<!-- Finally, let us have a loot at the notional cost for rescuing each of these animals. As the LFB says, -->

<!-- > Please note that any cost included is a notional cost calculated based on the length of time rounded up to the nearest hour spent by Pump, Aerial and FRU appliances at the incident and charged at the current Brigade hourly rate. -->

<!-- There is two things we will do: -->

<!-- 1. Calculate the mean and median `incident_notional_cost` for each `animal_group_parent` -->
<!-- 2. Plot a boxplot to get a feel for the distribution of `incident_notional_cost` by `animal_group_parent`. -->


<!-- Before we go on, however, we need to fix `incident_notional_cost` as it is stored as a `chr`, or character, rather than a number. -->

```{r, parse_incident_cost,message=FALSE, warning=FALSE}

# what type is variable incident_notional_cost from dataframe `animal_rescue`
typeof(animal_rescue$incident_notional_cost)

# readr::parse_number() will convert any numerical values stored as characters into numbers
animal_rescue <- animal_rescue %>% 

  # we use mutate() to use the parse_number() function and overwrite the same variable
  mutate(incident_notional_cost = parse_number(incident_notional_cost))

# incident_notional_cost from dataframe `animal_rescue` is now 'double' or numeric
typeof(animal_rescue$incident_notional_cost)

```

<!-- Now tht incident_notional_cost is numeric, let us quickly calculate summary statistics for each animal group.  -->


```{r, stats_on_incident_cost,message=FALSE, warning=FALSE}

animal_rescue %>% 
  
  # group by animal_group_parent
  group_by(animal_group_parent) %>% 
  
  # filter resulting data, so each group has at least 6 observations
  filter(n()>6) %>% 
  
  # summarise() will collapse all values into 3 values: the mean, median, and count  
  # we use na.rm=TRUE to make sure we remove any NAs, or cases where we do not have the incident cos
  summarise(mean_incident_cost = mean (incident_notional_cost, na.rm=TRUE),
            median_incident_cost = median (incident_notional_cost, na.rm=TRUE),
            sd_incident_cost = sd (incident_notional_cost, na.rm=TRUE),
            min_incident_cost = min (incident_notional_cost, na.rm=TRUE),
            max_incident_cost = max (incident_notional_cost, na.rm=TRUE),
            count = n()) %>% 
  
  # sort the resulting data in descending order. You choose whether to sort by count or mean cost.
  arrange(desc(mean_incident_cost))

```



<!-- Compare the mean and the median for each animal group. waht do you think this is telling us? -->
<!-- Anything else that stands out? Any outliers? -->

For most animal groups the mean incident cost is higher than the median incident cost. Hence, it can be deduced that a relatively small number of very expensive inciedents drive these higher mean values. For instance, a single very complex horse rescue action may be responsible for a considerable amount of the costs for this animal group. In general, it quite clear that animals with larger body volumes (i.e. horses, cows, deer) cause incidents with higher costs. These animals have more power to cause destruction or even injury. Another interesting observation is that the costs for unknown animal incidents rank among the highest. Finally, cat incidents seem to be relatively standard procedures and hence have relatively low mean incident costs.    

<!-- Finally, let us plot a few plots that show the distribution of incident_cost for each animal group. -->

```{r, plots_on_incident_cost_by_animal_group,message=FALSE, warning=FALSE}

# base_plot
base_plot <- animal_rescue %>% 
  group_by(animal_group_parent) %>% 
  filter(n()>6) %>% 
  ggplot(aes(x=incident_notional_cost))+
  facet_wrap(~animal_group_parent, scales = "free")+
  theme_bw()

base_plot + geom_histogram()
base_plot + geom_density()
base_plot + geom_boxplot()
base_plot + stat_ecdf(geom = "step", pad = FALSE) +
  scale_y_continuous(labels = scales::percent)



```

<!-- Which of these four graphs do you think best communicates the variability of the `incident_notional_cost` values? Also, can you please tell some sort of story (which animals are more expensive to rescue than others, the spread of values) and speculate about the differences in the patterns. -->

I find that the density plot best communicates the variability of the incident costs per animal group. It is both easily understandable and visually intuitive. In contrast to the histogram plot, the "smoothed" line further facilitates the expressiveness. For instance, it is immediately visible that the the costs of ferret incidents follow a very different distribution than those of squirrels. 

As previously stated, larger animals are clearly more expensive to rescue. For instance, horse rescues can costs 000s while rabbit rescues rarely exceed GBP 350. It can be speculated that the heavier equipment and higher number of required rescue personnel causes this difference in incident costs.  

In general, most animal groups follow a similar distribution. First, a large proportion of the incidents result in relatively low costs (though "low" clearly varies from animal group to animal group). For instance, most hamster incidents cost less than GBP 400. Similarly, most horse incidents cost less than GBP 1,200. Second, many animal groups show a small number of incidents that are relatively expensive. For instance, hamsters, squirrels, snakes, and heavy livestock all cause a small number of incidents that are rather expensive. It is easy to imagine that each of these animals can severely damage an expensive object (at least in a small number of the cases). 

The ferret and rabbit groups show slightly different cost distributions. Here, the proportion of incidents is more evenly distributed. These two groups have the lowest standard deviation for incident costs and it can be speculated that the incidents for these animal groups are relatively unspectacular and similar in nature. This explains the more even cost distributions.   

<!-- # Submit the assignment -->

<!-- Knit the completed R Markdown file as an HTML document (use the "Knit" button at the top of the script editor window) and upload it to Canvas. -->

<!-- ## Details -->

<!-- If you want to, please answer the following -->

<!-- -   Who did you collaborate with: / -->
<!-- -   Approximately how much time did you spend on this problem set: c. 4 hours -->
<!-- -   What, if anything, gave you the most trouble: / -->
